
#   å†™å…¥jsonæ–‡ä»¶çš„æ—¶å€™ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼š


##   ç¬¬ä¸€ç§æ˜¯ï¼Œä¸€è¡Œç´§æ¥ç€ä¸€è¡ŒæŒ¤ç€å†™å…¥ï¼Œè¿™æ—¶å°±éœ€æŒ‰ç¾åŒ–é”®æ¥åˆ†è¡Œï¼Œå³è¿™ç§å†™å…¥æ–¹å¼ä¸ºJavaScriptçš„æ ‡å‡†å†™æ³•


##   ç¬¬äºŒç§æ˜¯ï¼Œåˆ†è¡Œå†™ï¼Œè¿™æ—¶ç‰¹å®¹æ˜“é£˜çº¢æŠ¥é”™ï¼Œä½†æ˜¯ä¸è™šï¼Œèƒ½è¯»å°±å¯ä»¥ï¼Œè®©ä»–é£˜ï¼

>[!Note|lable:ç¬¬ä¸€ç§ï¼š] ä¸éœ€è¦è§£é‡Šå¤ªå¤šï¼Œå’±dumpsåŒ–ç„¶åå†™è¿›çš„æ—¶å€™å°±æ˜¯è¿™ç§ï¼Œå’±è¿›å»jsonæ–‡ä»¶ç¬¬ä¸€ä»¶äº‹å°±æ˜¯ç¾åŒ–ä¸æ˜¯ä¹ˆ

>[!Danger|lable:ç¬¬äºŒç§] æ–¹æ³•æœ‰å¾ˆå¤šç§æ¥å®ç°ï¼Œä»¥ä¸‹å’±ğŸ‘§ç›´æ¥ä¸Špythonä»£ç ï¼

 
-   ```python
    json_list=json.dumps(dictda,ensure_ascii=False)
    with open('json.json','a',encoding='utf-8',newline='')as f:
        f.write(json_list)
        f.write('\n')
    ```

-   ```python
    # >>>  scrapy pipelineé‡Œé¢çš„å†™å…¥æ—¶çš„æ–¹æ³•
    # >>>  å­˜json
    from scrapy.exporters import JsonItemExporter,JsonLinesItemExporter
    class MyprojectPipelineJson(object):


    def __init__(self):
        self.file=open('datas.json','wb')
        self.exporter = JsonLinesItemExporter(self.file,encoding='utf-8')
        self.exporter.start_exporting()
    
    def process_item(self,item,spider):
        self.exporter.export_item(item)
        # >>>  self.exporter.indent=1
        return item
    
    def close_spider(self,spider):
        self.exporter.finish_exporting()
        self.file.close()


    # >>>  è¿™é‡Œçš„JsonLinesItemExporteræˆ–è€… self.exporter.indent=1  éƒ½å¯ä»¥æ¢è¡Œ

    
    ```

# å­˜å…¥jsonæ—¶å‡ºç°ä¹±ç çš„è§£å†³åŠæ³•

##  requests
- å¤„ç†æ–¹æ³•ï¼š
- html.encoding = 'unicode_escape'
- æˆ–
- json.dumps(html.text,ensure_ascii=False)
##  scrapy
- å¤„ç†æ–¹æ³•ï¼š
- response.body.decode('unicode_escape')
- å› ä¸ºscrapyé»˜è®¤ç¼–ç ä¸æ˜¯asciiï¼Œè€Œæ˜¯åˆ«çš„

